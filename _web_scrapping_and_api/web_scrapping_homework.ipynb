{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "61ac38de",
   "metadata": {},
   "source": [
    "# Задание 1.\n",
    "Обязательная часть\n",
    "Будем парсить страницу со свежеми новостям на habr.com/ru/all/.\n",
    "\n",
    "Вам необходимо собирать только те статьи, в которых встречается хотя бы одно требуемое ключевое слово. Эти слова определяем в начале кода в переменной, например:\n",
    "\n",
    "KEYWORDS = ['python', 'парсинг']\n",
    "\n",
    "Поиск вести по всей доступной preview-информации (это информация, доступная непосредственно с текущей страницы).\n",
    "\n",
    "В итоге должен формироваться датафрейм вида: <дата> - <заголовок> - <ссылка>\n",
    "\n",
    "Дополнительная часть (необязательная)\n",
    "Улучшить скрипт так, чтобы он анализировал не только preview-информацию статьи, но и весь текст статьи целиком.\n",
    "\n",
    "Для этого потребуется получать страницы статей и искать по тексту внутри этой страницы.\n",
    "\n",
    "Итоговый датафрейм формировать со столбцами: <дата> - <заголовок> - <ссылка> - <текст_статьи>\n",
    "\n",
    "Дополнительная часть (необязательная)\n",
    "Улучшить скрипт так, чтобы он анализировал не только preview-информацию статьи, но и весь текст статьи целиком.\n",
    "\n",
    "Для этого потребуется получать страницы статей и искать по тексту внутри этой страницы.\n",
    "\n",
    "Итоговый датафрейм формировать со столбцами: <дата> - <заголовок> - <ссылка> - <текст_статьи>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1237,
   "id": "18eb83bd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>дата</th>\n",
       "      <th>заголовок</th>\n",
       "      <th>ссылка</th>\n",
       "      <th>текст статьи</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2021-07-22</td>\n",
       "      <td>За что я люблю ассемблер?</td>\n",
       "      <td>https://habr.com/ru/post/569204/</td>\n",
       "      <td>Этой статье уже почти 3 года. Однако сегодня я...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2021-07-22</td>\n",
       "      <td>Зарплаты в Data Science будут расти несмотря н...</td>\n",
       "      <td>https://habr.com/ru/company/skillfactory/blog/...</td>\n",
       "      <td>Оригинал первой части перевода вы найдёте здес...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2021-07-22</td>\n",
       "      <td>Опыт установки современного дистрибутива Linux...</td>\n",
       "      <td>https://habr.com/ru/post/569198/</td>\n",
       "      <td>Привет, Хабр!На reddit, в сообществах посвяще...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2021-07-22</td>\n",
       "      <td>Создание инцидента через бота MS Teams</td>\n",
       "      <td>https://habr.com/ru/post/569166/</td>\n",
       "      <td>Повышение осведомленности работников в области...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2021-07-22</td>\n",
       "      <td>Golang+FFmpeg</td>\n",
       "      <td>https://habr.com/ru/post/569162/</td>\n",
       "      <td>Долго искал более-менее живую Golang-библиотек...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2021-07-22</td>\n",
       "      <td>Сейчас я вас научу, как именно бояться стомато...</td>\n",
       "      <td>https://habr.com/ru/company/belayaraduga/blog/...</td>\n",
       "      <td>Главный врач</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         дата                                          заголовок  \\\n",
       "0  2021-07-22                          За что я люблю ассемблер?   \n",
       "0  2021-07-22  Зарплаты в Data Science будут расти несмотря н...   \n",
       "0  2021-07-22  Опыт установки современного дистрибутива Linux...   \n",
       "0  2021-07-22             Создание инцидента через бота MS Teams   \n",
       "0  2021-07-22                                      Golang+FFmpeg   \n",
       "0  2021-07-22  Сейчас я вас научу, как именно бояться стомато...   \n",
       "\n",
       "                                              ссылка  \\\n",
       "0                   https://habr.com/ru/post/569204/   \n",
       "0  https://habr.com/ru/company/skillfactory/blog/...   \n",
       "0                   https://habr.com/ru/post/569198/   \n",
       "0                   https://habr.com/ru/post/569166/   \n",
       "0                   https://habr.com/ru/post/569162/   \n",
       "0  https://habr.com/ru/company/belayaraduga/blog/...   \n",
       "\n",
       "                                        текст статьи  \n",
       "0  Этой статье уже почти 3 года. Однако сегодня я...  \n",
       "0  Оригинал первой части перевода вы найдёте здес...  \n",
       "0   Привет, Хабр!На reddit, в сообществах посвяще...  \n",
       "0  Повышение осведомленности работников в области...  \n",
       "0  Долго искал более-менее живую Golang-библиотек...  \n",
       "0                                       Главный врач  "
      ]
     },
     "execution_count": 1237,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import time\n",
    "import pandas as pd\n",
    "#определяем ключевые слова для дальнейшего поиска по ним статей\n",
    "KEYWORDS = ['science','linux','azure','js','страх']\n",
    "# получаем страницу с самыми свежими постами\n",
    "req = requests.get('https://habr.com/ru/all/')\n",
    "soup = BeautifulSoup(req.text, 'html.parser')\n",
    "# извлекаем посты\n",
    "posts = soup.find_all('div', class_='tm-article-snippet')\n",
    "habr_frame = pd.DataFrame()\n",
    "habr_frame_new = pd.DataFrame()\n",
    "# проходимся в цикле по всем статьям\n",
    "for post in posts:\n",
    "    date = post.find('span', class_='tm-article-snippet__datetime-published')\n",
    "    head = post.find('h2', class_='tm-article-snippet__title tm-article-snippet__title_h2')\n",
    "    #переходим по полученой нами ссылке статьи и вытягиваем оттуда текст статьи\n",
    "    link_full= 'https://habr.com' + head.a.get('href') \n",
    "    req_link = requests.get(link_full)\n",
    "    soup_link = BeautifulSoup(req_link.text, 'html.parser')\n",
    "    #hubs -это текст статьи с тегами (может быть оформлена двумя классами ...version-1 и version-2)\n",
    "    hubs1 = soup_link.find_all('div', class_='article-formatted-body article-formatted-body_version-1') \n",
    "    hubs= hubs1 + soup_link.find_all('div', class_='article-formatted-body article-formatted-body_version-2')\n",
    "    #разбиваем на слова статьи \n",
    "    for hub in hubs: \n",
    "        hub_lower = hub.text.lower()\n",
    "        hubs_list = hub_lower.split(' ')\n",
    "        #сравниваем каждое слово в превьюшке статьи с нашим словариком\n",
    "        for word in hubs_list:\n",
    "            if word in KEYWORDS:\n",
    "                date_short = pd.to_datetime(date.time.get('title')).date()\n",
    "                habr_frame['дата']= [date_short]\n",
    "                link_full= 'https://habr.com' + head.a.get('href')    \n",
    "                habr_frame['заголовок']= [head.text] \n",
    "                habr_frame['ссылка']= [link_full] \n",
    "                #вытягиваем из soup текст статьи по тегам 'p'\n",
    "                text_draft = soup_link.find_all('p')\n",
    "                #поблочно перебираем статью и отчищаем от тегов для сохранения в датафрейме\n",
    "                text_all = ''\n",
    "                for word in text_draft: \n",
    "                    text_all = text_all+word.text\n",
    "                habr_frame['текст статьи']= [text_all]\n",
    "                habr_frame_new = pd.concat([habr_frame_new,habr_frame])\n",
    "#удаляем дубликаты статей и выводим датафрейм\n",
    "habr_frame_new.drop_duplicates('заголовок', keep=\"first\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc3e6658",
   "metadata": {},
   "source": [
    "# Задание 2.\n",
    "\n",
    "Обязательная часть\n",
    "Написать скрипт, который будет проверять список e-mail адресов на утечку при помощи сервиса Avast Hack Ckeck. Список email-ов задаем переменной в начале кода:\n",
    "EMAIL = [xxx@x.ru, yyy@y.com]\n",
    "\n",
    "В итоге должен формироваться датафрейм со столбцами: <дата утечки> - <источник утечки> - <описание утечки>\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1136,
   "id": "bcb4251b",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'emailAddresses': ['xxx@x.ru']}\n",
      "{'emailAddresses': ['yyy@y.com']}\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>дата утечки</th>\n",
       "      <th>источник утечки</th>\n",
       "      <th>описание утечки</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2016-10-21T00:00:00Z</td>\n",
       "      <td>adobe.com</td>\n",
       "      <td>In October of 2013, criminals penetrated Adobe...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2016-10-29T00:00:00Z</td>\n",
       "      <td>vk.com</td>\n",
       "      <td>Popular Russian social networking platform VKo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2016-10-23T00:00:00Z</td>\n",
       "      <td>imesh.com</td>\n",
       "      <td>In June 2016, a cache of over 51 million user ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2017-01-31T00:00:00Z</td>\n",
       "      <td>cdprojektred.com</td>\n",
       "      <td>In March 2016, CDProjektRed.com.com's forum da...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2017-02-14T00:00:00Z</td>\n",
       "      <td>cfire.mail.ru</td>\n",
       "      <td>In July and August of 2016, two criminals carr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2017-02-14T00:00:00Z</td>\n",
       "      <td>parapa.mail.ru</td>\n",
       "      <td>In July and August 2016, two criminals execute...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2016-10-21T00:00:00Z</td>\n",
       "      <td>linkedin.com</td>\n",
       "      <td>In 2012, online professional networking platfo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2016-10-21T00:00:00Z</td>\n",
       "      <td>adobe.com</td>\n",
       "      <td>In October of 2013, criminals penetrated Adobe...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2016-10-23T00:00:00Z</td>\n",
       "      <td>imesh.com</td>\n",
       "      <td>In June 2016, a cache of over 51 million user ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2016-10-24T00:00:00Z</td>\n",
       "      <td>dropbox.com</td>\n",
       "      <td>Cloud storage company Dropbox suffered a major...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2017-03-15T00:00:00Z</td>\n",
       "      <td>globalreach.eu</td>\n",
       "      <td>In 2016, Global Reach Technology's database wa...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2017-03-01T00:00:00Z</td>\n",
       "      <td>rayli.com.cn</td>\n",
       "      <td>On an unconfirmed date, Chinese gossip site Ra...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2017-03-24T00:00:00Z</td>\n",
       "      <td>youku.com</td>\n",
       "      <td>Youku is a large Chinese video content company...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2017-11-04T00:00:00Z</td>\n",
       "      <td>myheritage.com</td>\n",
       "      <td>In October 2017, a customer database belonging...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2018-02-18T00:00:00Z</td>\n",
       "      <td>netlog.com</td>\n",
       "      <td>Netlog (formerly known as Facebox and Bingbox)...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2019-06-13T00:00:00Z</td>\n",
       "      <td>canva.com</td>\n",
       "      <td>In May 2019, graphic-design site Canva's datab...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2019-10-17T00:00:00Z</td>\n",
       "      <td>zynga.com</td>\n",
       "      <td>In September 2019, the game developer Zynga wa...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2020-01-03T00:00:00Z</td>\n",
       "      <td>azcentral.com</td>\n",
       "      <td>At an unconfirmed date, online Arizona newspap...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2020-05-28T00:00:00Z</td>\n",
       "      <td>wishbone.io</td>\n",
       "      <td>In January 2020, the online poll website Wishb...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2021-02-11T00:00:00Z</td>\n",
       "      <td>forums.vkmonline.com</td>\n",
       "      <td>At an unconfirmed date, the Russian-language m...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            дата утечки       источник утечки  \\\n",
       "0  2016-10-21T00:00:00Z             adobe.com   \n",
       "0  2016-10-29T00:00:00Z                vk.com   \n",
       "0  2016-10-23T00:00:00Z             imesh.com   \n",
       "0  2017-01-31T00:00:00Z      cdprojektred.com   \n",
       "0  2017-02-14T00:00:00Z         cfire.mail.ru   \n",
       "0  2017-02-14T00:00:00Z        parapa.mail.ru   \n",
       "0  2016-10-21T00:00:00Z          linkedin.com   \n",
       "0  2016-10-21T00:00:00Z             adobe.com   \n",
       "0  2016-10-23T00:00:00Z             imesh.com   \n",
       "0  2016-10-24T00:00:00Z           dropbox.com   \n",
       "0  2017-03-15T00:00:00Z        globalreach.eu   \n",
       "0  2017-03-01T00:00:00Z          rayli.com.cn   \n",
       "0  2017-03-24T00:00:00Z             youku.com   \n",
       "0  2017-11-04T00:00:00Z        myheritage.com   \n",
       "0  2018-02-18T00:00:00Z            netlog.com   \n",
       "0  2019-06-13T00:00:00Z             canva.com   \n",
       "0  2019-10-17T00:00:00Z             zynga.com   \n",
       "0  2020-01-03T00:00:00Z         azcentral.com   \n",
       "0  2020-05-28T00:00:00Z           wishbone.io   \n",
       "0  2021-02-11T00:00:00Z  forums.vkmonline.com   \n",
       "\n",
       "                                     описание утечки  \n",
       "0  In October of 2013, criminals penetrated Adobe...  \n",
       "0  Popular Russian social networking platform VKo...  \n",
       "0  In June 2016, a cache of over 51 million user ...  \n",
       "0  In March 2016, CDProjektRed.com.com's forum da...  \n",
       "0  In July and August of 2016, two criminals carr...  \n",
       "0  In July and August 2016, two criminals execute...  \n",
       "0  In 2012, online professional networking platfo...  \n",
       "0  In October of 2013, criminals penetrated Adobe...  \n",
       "0  In June 2016, a cache of over 51 million user ...  \n",
       "0  Cloud storage company Dropbox suffered a major...  \n",
       "0  In 2016, Global Reach Technology's database wa...  \n",
       "0  On an unconfirmed date, Chinese gossip site Ra...  \n",
       "0  Youku is a large Chinese video content company...  \n",
       "0  In October 2017, a customer database belonging...  \n",
       "0  Netlog (formerly known as Facebox and Bingbox)...  \n",
       "0  In May 2019, graphic-design site Canva's datab...  \n",
       "0  In September 2019, the game developer Zynga wa...  \n",
       "0  At an unconfirmed date, online Arizona newspap...  \n",
       "0  In January 2020, the online poll website Wishb...  \n",
       "0  At an unconfirmed date, the Russian-language m...  "
      ]
     },
     "execution_count": 1136,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import requests\n",
    "import time\n",
    "\n",
    "\n",
    "URL = 'https://identityprotection.avast.com/v1/web/query/site-breaches/unauthorized-data'\n",
    "HEADERS = {\n",
    "    \n",
    "            'Accept-Encoding': 'gzip, deflate, br',\n",
    "            'Accept-Language': 'ru-RU,ru;q=0.9,pl-PL;q=0.8,pl;q=0.7,en-US;q=0.6,en;q=0.5',\n",
    "            'Connection': 'keep-alive',\n",
    "            'Content-Length': '31',\n",
    "            'Content-Type': 'application/json;charset=UTF-8',\n",
    "            'Host': 'identityprotection.avast.com',\n",
    "            'Origin': 'https://www.avast.com',\n",
    "            'Referer': 'https://www.avast.com/',\n",
    "            'sec-ch-ua': '\" Not;A Brand\";v=\"99\", \"Google Chrome\";v=\"91\", \"Chromium\";v=\"91\"',\n",
    "            'sec-ch-ua-mobile': '?0',\n",
    "            'Sec-Fetch-Dest': 'empty',\n",
    "            'Sec-Fetch-Mode': 'cors',\n",
    "            'Sec-Fetch-Site': 'same-site',\n",
    "            'User-Agent': 'Mozilla/4.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.114 Safari/537.36',\n",
    "            'Vaar-Header-App-Build-Version': '1.0.0',\n",
    "            'Vaar-Header-App-Product': 'hackcheck-web-avast',\n",
    "            'Vaar-Header-App-Product-Name': 'hackcheck-web-avast',\n",
    "            'Vaar-Version': '0'\n",
    "}\n",
    "EMAILS = {\n",
    "    'emailAddresses': ['xxx@x.ru']\n",
    "}\n",
    "EMAIL = ['xxx@x.ru','yyy@y.com']\n",
    "leaks_frame = pd.DataFrame()\n",
    "leaks_frame_new = pd.DataFrame()\n",
    "for i in range(len(EMAIL)):\n",
    "    EMAILS['emailAddresses'] = [EMAIL[i]]\n",
    "    print(EMAILS)\n",
    "    r = requests.post(URL, headers=HEADERS, json=EMAILS)\n",
    "    time.sleep(5)\n",
    "    #print(r)\n",
    "    respond = r.json()\n",
    "\n",
    "    for x in respond['breaches'].keys():\n",
    "        leaks_frame['дата утечки']= [respond['breaches'][x]['publishDate']] \n",
    "        leaks_frame['источник утечки']= [respond['breaches'][x]['site']] \n",
    "        leaks_frame['описание утечки']= [respond['breaches'][x]['description']]\n",
    "        leaks_frame_new = pd.concat([leaks_frame_new,leaks_frame])\n",
    "leaks_frame_new "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff980a79",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
