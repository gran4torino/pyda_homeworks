{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "33b766be",
   "metadata": {},
   "source": [
    "# Домашнее задание к лекции \"Статистика. Практика\"\n",
    "\n",
    "## Задание 1\n",
    "\n",
    "Вернемся к [набору данных о видеоиграх](https://github.com/obulygin/pyda_homeworks/blob/master/stat_case_study/vgsales.csv).\n",
    "\n",
    "Ответьте на следующие вопросы:\n",
    "\n",
    "1) Как критики относятся к спортивным играм?  \n",
    "2) Критикам нравятся больше игры на PC или на PS4?  \n",
    "3) Критикам больше нравятся стрелялки или стратегии?  \n",
    "\n",
    "Для каждого вопроса:\n",
    "- сформулируйте нулевую и альтернативную гипотезы;\n",
    "- выберите пороговый уровень статистической значимости;\n",
    "- опишите полученные результаты статистического теста."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ac7ad340",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np  \n",
    "import pandas as pd  # для работы с таблицами\n",
    "from scipy import stats as st # для работы со статистикой\n",
    "import matplotlib.pyplot as plt  # Библиотека для визуализации результатов \n",
    "import seaborn as sns # Более продвинутая библиотека для визуализации"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c645a68e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name</th>\n",
       "      <th>Platform</th>\n",
       "      <th>Year_of_Release</th>\n",
       "      <th>Genre</th>\n",
       "      <th>Publisher</th>\n",
       "      <th>NA_Sales</th>\n",
       "      <th>EU_Sales</th>\n",
       "      <th>JP_Sales</th>\n",
       "      <th>Other_Sales</th>\n",
       "      <th>Global_Sales</th>\n",
       "      <th>Critic_Score</th>\n",
       "      <th>Critic_Count</th>\n",
       "      <th>User_Score</th>\n",
       "      <th>User_Count</th>\n",
       "      <th>Developer</th>\n",
       "      <th>Rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Wii Sports</td>\n",
       "      <td>Wii</td>\n",
       "      <td>2006.0</td>\n",
       "      <td>Sports</td>\n",
       "      <td>Nintendo</td>\n",
       "      <td>41.36</td>\n",
       "      <td>28.96</td>\n",
       "      <td>3.77</td>\n",
       "      <td>8.45</td>\n",
       "      <td>82.53</td>\n",
       "      <td>76.0</td>\n",
       "      <td>51.0</td>\n",
       "      <td>8</td>\n",
       "      <td>322.0</td>\n",
       "      <td>Nintendo</td>\n",
       "      <td>E</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Super Mario Bros.</td>\n",
       "      <td>NES</td>\n",
       "      <td>1985.0</td>\n",
       "      <td>Platform</td>\n",
       "      <td>Nintendo</td>\n",
       "      <td>29.08</td>\n",
       "      <td>3.58</td>\n",
       "      <td>6.81</td>\n",
       "      <td>0.77</td>\n",
       "      <td>40.24</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Mario Kart Wii</td>\n",
       "      <td>Wii</td>\n",
       "      <td>2008.0</td>\n",
       "      <td>Racing</td>\n",
       "      <td>Nintendo</td>\n",
       "      <td>15.68</td>\n",
       "      <td>12.76</td>\n",
       "      <td>3.79</td>\n",
       "      <td>3.29</td>\n",
       "      <td>35.52</td>\n",
       "      <td>82.0</td>\n",
       "      <td>73.0</td>\n",
       "      <td>8.3</td>\n",
       "      <td>709.0</td>\n",
       "      <td>Nintendo</td>\n",
       "      <td>E</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Wii Sports Resort</td>\n",
       "      <td>Wii</td>\n",
       "      <td>2009.0</td>\n",
       "      <td>Sports</td>\n",
       "      <td>Nintendo</td>\n",
       "      <td>15.61</td>\n",
       "      <td>10.93</td>\n",
       "      <td>3.28</td>\n",
       "      <td>2.95</td>\n",
       "      <td>32.77</td>\n",
       "      <td>80.0</td>\n",
       "      <td>73.0</td>\n",
       "      <td>8</td>\n",
       "      <td>192.0</td>\n",
       "      <td>Nintendo</td>\n",
       "      <td>E</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Pokemon Red/Pokemon Blue</td>\n",
       "      <td>GB</td>\n",
       "      <td>1996.0</td>\n",
       "      <td>Role-Playing</td>\n",
       "      <td>Nintendo</td>\n",
       "      <td>11.27</td>\n",
       "      <td>8.89</td>\n",
       "      <td>10.22</td>\n",
       "      <td>1.00</td>\n",
       "      <td>31.37</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       Name Platform  Year_of_Release         Genre Publisher  \\\n",
       "0                Wii Sports      Wii           2006.0        Sports  Nintendo   \n",
       "1         Super Mario Bros.      NES           1985.0      Platform  Nintendo   \n",
       "2            Mario Kart Wii      Wii           2008.0        Racing  Nintendo   \n",
       "3         Wii Sports Resort      Wii           2009.0        Sports  Nintendo   \n",
       "4  Pokemon Red/Pokemon Blue       GB           1996.0  Role-Playing  Nintendo   \n",
       "\n",
       "   NA_Sales  EU_Sales  JP_Sales  Other_Sales  Global_Sales  Critic_Score  \\\n",
       "0     41.36     28.96      3.77         8.45         82.53          76.0   \n",
       "1     29.08      3.58      6.81         0.77         40.24           NaN   \n",
       "2     15.68     12.76      3.79         3.29         35.52          82.0   \n",
       "3     15.61     10.93      3.28         2.95         32.77          80.0   \n",
       "4     11.27      8.89     10.22         1.00         31.37           NaN   \n",
       "\n",
       "   Critic_Count User_Score  User_Count Developer Rating  \n",
       "0          51.0          8       322.0  Nintendo      E  \n",
       "1           NaN        NaN         NaN       NaN    NaN  \n",
       "2          73.0        8.3       709.0  Nintendo      E  \n",
       "3          73.0          8       192.0  Nintendo      E  \n",
       "4           NaN        NaN         NaN       NaN    NaN  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_csv('vgsales.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38028e1a",
   "metadata": {},
   "source": [
    "**1. Как критики относятся к спортивным играм?**\n",
    "\n",
    "H0: Критики плохо относятся к спортивным играм. Средний рейтинг критиков  < 50\n",
    "\n",
    "H1: Критики хорошо относятся к спортивным играм. Средний рейтинг критиков  >= 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "074916f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "71.96817420435511\n",
      "Ttest_1sampResult(statistic=54.696017932916575, pvalue=0.0)\n",
      "Отвергаем нулевую гипотезу, среднее больше 50. Критики хорошо относятся к спортивным играм\n"
     ]
    }
   ],
   "source": [
    "alpha = 0.05\n",
    "#Сравниваем значение по выборке с константой, поэтому нужен одновыборочный критерий.\n",
    "result = st.ttest_1samp(df[df['Genre'] == 'Sports']['Critic_Score'].dropna(), 50, alternative='greater')\n",
    "\n",
    "print(df[df['Genre'] == 'Sports']['Critic_Score'].mean())\n",
    "print(result)\n",
    "\n",
    "if result.pvalue < alpha:\n",
    "    print('Отвергаем нулевую гипотезу, среднее больше 50. Критики хорошо относятся к спортивным играм' )\n",
    "else:\n",
    "    print('Не отвергаем нулевую гипотезу. Критики плохо относятся к спортивным играм')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d132b74",
   "metadata": {},
   "source": [
    "**2. Критикам нравятся больше игры на PC или на PS4?**\n",
    "\n",
    "Используем двухвыборочный двухсторонний критерий"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f74f2eae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "75.92867132867133\n",
      "72.09126984126983\n",
      "Ttest_indResult(statistic=4.3087588262138725, pvalue=2.0672491572827482e-05)\n",
      "Выборки статистически различаются.\n",
      "Критикам  нравятся больше игры на PC, чем на PS4.\n"
     ]
    }
   ],
   "source": [
    "A1 = df[df['Platform'] == 'PC']['Critic_Score']\n",
    "A2 = df[df['Platform'] == 'PS4']['Critic_Score']\n",
    "\n",
    "# выдвинем гипотезу\n",
    "H0 = ' Выборки статистически не различаются.'\n",
    "H1 =  'Выборки статистически различаются.'\n",
    "A1_version = 'Критикам  нравятся больше игры на PC, чем на PS4.'\n",
    "A2_version = 'Критикам  нравятся больше игры на PS4, чем на PC.'\n",
    "result = st.ttest_ind(A1,A2, equal_var=False, nan_policy='omit')\n",
    "print(A1.mean())\n",
    "print(A2.mean())\n",
    "\n",
    "print(result)\n",
    "\n",
    "if (result.pvalue < alpha):\n",
    "    print(H1)\n",
    "    if result.statistic > 0:\n",
    "        print(A1_version)\n",
    "    else:\n",
    "        print(A2_version)\n",
    "else:\n",
    "    print(H0)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f532b79c",
   "metadata": {},
   "source": [
    "**3.Критикам больше нравятся стрелялки или стратегии?**\n",
    "\n",
    "\n",
    "Используем двухвыборочный сторонний критерий"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2a8b1e90",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "70.18114406779661\n",
      "72.08609271523179\n",
      "Ttest_indResult(statistic=-2.2972408230640315, pvalue=0.021938989522305212)\n",
      "Выборки статистически различаются.\n",
      "Критикам больше нравятся стратегии, чем стрелялки.\n"
     ]
    }
   ],
   "source": [
    "A1 = df[df['Genre'] == 'Shooter']['Critic_Score']\n",
    "A2 = df[df['Genre'] == 'Strategy']['Critic_Score']\n",
    "\n",
    "# выдвинем гипотезу\n",
    "H0 = ' Выборки статистически не различаются.'\n",
    "H1 =  'Выборки статистически различаются.'\n",
    "A1_version = 'Критикам больше нравятся стрелялки, чем стратегии'\n",
    "A2_version = 'Критикам больше нравятся стратегии, чем стрелялки.'\n",
    "result = st.ttest_ind(A1,A2, equal_var=False, nan_policy='omit')\n",
    "print(A1.mean())\n",
    "print(A2.mean())\n",
    "\n",
    "print(result)\n",
    "\n",
    "if (result.pvalue < alpha):\n",
    "    print(H1)\n",
    "    if result.statistic > 0:\n",
    "        print(A1_version)\n",
    "    else:\n",
    "        print(A2_version)\n",
    "else:\n",
    "    print(H0)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9fefecc",
   "metadata": {},
   "source": [
    "## Задание 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd8fcc93",
   "metadata": {},
   "source": [
    "Реализуйте базовую модель логистической регрессии для классификации текстовых сообщений (используемые данные [здесь](https://github.com/obulygin/pyda_homeworks/blob/master/stat_case_study/spam.csv)) по признаку спама. Для этого:\n",
    "\n",
    "1) Привидите весь текст к нижнему регистру;  \n",
    "2) Удалите мусорные символы;  \n",
    "3) Удалите стоп-слова;  \n",
    "4) Привидите все слова к нормальной форме;  \n",
    "5) Преобразуйте все сообщения в вектора TF-IDF. Вам поможет следующий код:  \n",
    "\n",
    "```\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "tfidf = TfidfVectorizer()\n",
    "tfidf_matrix = tfidf.fit_transform(df.Message)\n",
    "names = tfidf.get_feature_names()\n",
    "tfidf_matrix = pd.DataFrame(tfidf_matrix.toarray(), columns=names)\n",
    "```\n",
    "\n",
    "Можете поэкспериментировать с параметрами [TfidfVectorizer](https://scikit-learn.org/stable/modules/generated/sklearn.feature_extraction.text.TfidfVectorizer.html);  \n",
    "\n",
    "6) Разделите данные на тестовые и тренировочные в соотношении 30/70, укажите `random_state=42`. Используйте [train_test_split](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.train_test_split.html);  \n",
    "\n",
    "7) Постройте модель [логистической регрессии](https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LogisticRegression.html), укажите `random_state=42`, оцените ее точность на тестовых данных;  \n",
    "\n",
    "8) Опишите результаты при помощи [confusion_matrix](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.confusion_matrix.html?highlight=confusion_matrix#sklearn.metrics.confusion_matrix);  \n",
    "\n",
    "9) Постройте датафрейм, который будет содержать все исходные тексты сообщений, классифицированные неправильно (с указанием фактического и предсказанного)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "id": "a9ac23ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# импорт библиотек\n",
    "import glob\n",
    "import pandas as pd\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "id": "cfaacff8",
   "metadata": {},
   "outputs": [],
   "source": [
    "df= pd.read_csv('spam.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "id": "66aade63",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Category</th>\n",
       "      <th>Message</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ham</td>\n",
       "      <td>Go until jurong point, crazy.. Available only ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ham</td>\n",
       "      <td>Ok lar... Joking wif u oni...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>spam</td>\n",
       "      <td>Free entry in 2 a wkly comp to win FA Cup fina...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ham</td>\n",
       "      <td>U dun say so early hor... U c already then say...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ham</td>\n",
       "      <td>Nah I don't think he goes to usf, he lives aro...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Category                                            Message\n",
       "0      ham  Go until jurong point, crazy.. Available only ...\n",
       "1      ham                      Ok lar... Joking wif u oni...\n",
       "2     spam  Free entry in 2 a wkly comp to win FA Cup fina...\n",
       "3      ham  U dun say so early hor... U c already then say...\n",
       "4      ham  Nah I don't think he goes to usf, he lives aro..."
      ]
     },
     "execution_count": 259,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "id": "548b8a6d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Category</th>\n",
       "      <th>Message</th>\n",
       "      <th>Message_clear</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ham</td>\n",
       "      <td>Go until jurong point, crazy.. Available only ...</td>\n",
       "      <td>go until jurong point, crazy.. available only ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ham</td>\n",
       "      <td>Ok lar... Joking wif u oni...</td>\n",
       "      <td>ok lar... joking wif u oni...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>spam</td>\n",
       "      <td>Free entry in 2 a wkly comp to win FA Cup fina...</td>\n",
       "      <td>free entry in 2 a wkly comp to win fa cup fina...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ham</td>\n",
       "      <td>U dun say so early hor... U c already then say...</td>\n",
       "      <td>u dun say so early hor... u c already then say...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ham</td>\n",
       "      <td>Nah I don't think he goes to usf, he lives aro...</td>\n",
       "      <td>nah i don't think he goes to usf, he lives aro...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Category                                            Message  \\\n",
       "0      ham  Go until jurong point, crazy.. Available only ...   \n",
       "1      ham                      Ok lar... Joking wif u oni...   \n",
       "2     spam  Free entry in 2 a wkly comp to win FA Cup fina...   \n",
       "3      ham  U dun say so early hor... U c already then say...   \n",
       "4      ham  Nah I don't think he goes to usf, he lives aro...   \n",
       "\n",
       "                                       Message_clear  \n",
       "0  go until jurong point, crazy.. available only ...  \n",
       "1                      ok lar... joking wif u oni...  \n",
       "2  free entry in 2 a wkly comp to win fa cup fina...  \n",
       "3  u dun say so early hor... u c already then say...  \n",
       "4  nah i don't think he goes to usf, he lives aro...  "
      ]
     },
     "execution_count": 260,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#1.Привидите весь текст к нижнему регистру\n",
    "df['Message_clear'] = df['Message'].str.lower()\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "id": "8861dead",
   "metadata": {},
   "outputs": [],
   "source": [
    "#2.Удалите мусорные символы\n",
    "df['Message_clear'].replace('[\\W_]+',' ',regex=True, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "id": "6350dc07",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Category</th>\n",
       "      <th>Message</th>\n",
       "      <th>Message_clear</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ham</td>\n",
       "      <td>Go until jurong point, crazy.. Available only ...</td>\n",
       "      <td>go until jurong point crazy available only in ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ham</td>\n",
       "      <td>Ok lar... Joking wif u oni...</td>\n",
       "      <td>ok lar joking wif u oni</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>spam</td>\n",
       "      <td>Free entry in 2 a wkly comp to win FA Cup fina...</td>\n",
       "      <td>free entry in 2 a wkly comp to win fa cup fina...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ham</td>\n",
       "      <td>U dun say so early hor... U c already then say...</td>\n",
       "      <td>u dun say so early hor u c already then say</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ham</td>\n",
       "      <td>Nah I don't think he goes to usf, he lives aro...</td>\n",
       "      <td>nah i don t think he goes to usf he lives arou...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Category                                            Message  \\\n",
       "0      ham  Go until jurong point, crazy.. Available only ...   \n",
       "1      ham                      Ok lar... Joking wif u oni...   \n",
       "2     spam  Free entry in 2 a wkly comp to win FA Cup fina...   \n",
       "3      ham  U dun say so early hor... U c already then say...   \n",
       "4      ham  Nah I don't think he goes to usf, he lives aro...   \n",
       "\n",
       "                                       Message_clear  \n",
       "0  go until jurong point crazy available only in ...  \n",
       "1                           ok lar joking wif u oni   \n",
       "2  free entry in 2 a wkly comp to win fa cup fina...  \n",
       "3       u dun say so early hor u c already then say   \n",
       "4  nah i don t think he goes to usf he lives arou...  "
      ]
     },
     "execution_count": 262,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "id": "f5531b3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords\n",
    "stopwords_set = set(stopwords.words('english'))\n",
    "from nltk.stem import WordNetLemmatizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "id": "72a07ac2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Запустим цикл, где уберем из текста все стоп-слова\n",
    "#проходимся по всем строчкам датафрейма, разделяем содержимое строки на слова, записываем список в переменную words\n",
    "for index, row in df.iterrows():\n",
    "    words = row['Message_clear'].split(' ')\n",
    "    # перебираем все слова из списка words и ищем их вхождение в список стоп-слов stopwords_set. \n",
    "    # если совпадение есть, удаляем из переменной words это слово\n",
    "    for word in words:\n",
    "        if word in stopwords_set:\n",
    "            words.remove(word)   \n",
    "    #записываем в датафрейм очищенный текст\n",
    "    row['Message_clear'] = words\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 265,
   "id": "3863ee1b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Category</th>\n",
       "      <th>Message</th>\n",
       "      <th>Message_clear</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ham</td>\n",
       "      <td>Go until jurong point, crazy.. Available only ...</td>\n",
       "      <td>[go, jurong, point, crazy, available, in, bugi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ham</td>\n",
       "      <td>Ok lar... Joking wif u oni...</td>\n",
       "      <td>[ok, lar, joking, wif, u, oni, ]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>spam</td>\n",
       "      <td>Free entry in 2 a wkly comp to win FA Cup fina...</td>\n",
       "      <td>[free, entry, 2, wkly, comp, win, fa, cup, fin...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ham</td>\n",
       "      <td>U dun say so early hor... U c already then say...</td>\n",
       "      <td>[u, dun, say, early, hor, u, c, already, say, ]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ham</td>\n",
       "      <td>Nah I don't think he goes to usf, he lives aro...</td>\n",
       "      <td>[nah, don, think, goes, usf, lives, around, th...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Category                                            Message  \\\n",
       "0      ham  Go until jurong point, crazy.. Available only ...   \n",
       "1      ham                      Ok lar... Joking wif u oni...   \n",
       "2     spam  Free entry in 2 a wkly comp to win FA Cup fina...   \n",
       "3      ham  U dun say so early hor... U c already then say...   \n",
       "4      ham  Nah I don't think he goes to usf, he lives aro...   \n",
       "\n",
       "                                       Message_clear  \n",
       "0  [go, jurong, point, crazy, available, in, bugi...  \n",
       "1                   [ok, lar, joking, wif, u, oni, ]  \n",
       "2  [free, entry, 2, wkly, comp, win, fa, cup, fin...  \n",
       "3    [u, dun, say, early, hor, u, c, already, say, ]  \n",
       "4  [nah, don, think, goes, usf, lives, around, th...  "
      ]
     },
     "execution_count": 265,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 266,
   "id": "e6d536b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#4 Привидите все слова к нормальной форме;\n",
    "#произведем лемматизацию\n",
    "\n",
    "#Лемматизация — процесс приведения словоформы к лемме — её нормальной (словарной) форме. \n",
    "#В русском языке:\n",
    "#- для существительных — именительный падеж, единственное число;\n",
    "#- для прилагательных — именительный падеж, единственное число, мужской род;\n",
    "#- для глаголов, причастий, деепричастий — глагол в инфинитиве несовершенного вида.\n",
    "#\n",
    "#В других языках – по аналогии.\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "lemmatizer= WordNetLemmatizer()\n",
    "\n",
    "for index, row in df.iterrows():\n",
    "    words_list = row['Message_clear']\n",
    "    \n",
    "    for i in range(len(words_list)):\n",
    "        words_list[i] = lemmatizer.lemmatize(words_list[i]) \n",
    "        #преобразуем список в строку и записываем его в датафрейм очищенную строчку\n",
    "    str1 = ' '.join(words_list)\n",
    "    row['Message_clear'] = str1\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 279,
   "id": "d1ade348",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Category</th>\n",
       "      <th>Message</th>\n",
       "      <th>Message_clear</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ham</td>\n",
       "      <td>Go until jurong point, crazy.. Available only ...</td>\n",
       "      <td>go jurong point crazy available in bugis n gre...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ham</td>\n",
       "      <td>Ok lar... Joking wif u oni...</td>\n",
       "      <td>ok lar joking wif u oni</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>spam</td>\n",
       "      <td>Free entry in 2 a wkly comp to win FA Cup fina...</td>\n",
       "      <td>free entry 2 wkly comp win fa cup final tkts 2...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ham</td>\n",
       "      <td>U dun say so early hor... U c already then say...</td>\n",
       "      <td>u dun say early hor u c already say</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ham</td>\n",
       "      <td>Nah I don't think he goes to usf, he lives aro...</td>\n",
       "      <td>nah don think go usf life around though</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Category                                            Message  \\\n",
       "0      ham  Go until jurong point, crazy.. Available only ...   \n",
       "1      ham                      Ok lar... Joking wif u oni...   \n",
       "2     spam  Free entry in 2 a wkly comp to win FA Cup fina...   \n",
       "3      ham  U dun say so early hor... U c already then say...   \n",
       "4      ham  Nah I don't think he goes to usf, he lives aro...   \n",
       "\n",
       "                                       Message_clear  \n",
       "0  go jurong point crazy available in bugis n gre...  \n",
       "1                           ok lar joking wif u oni   \n",
       "2  free entry 2 wkly comp win fa cup final tkts 2...  \n",
       "3               u dun say early hor u c already say   \n",
       "4            nah don think go usf life around though  "
      ]
     },
     "execution_count": 279,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 844,
   "id": "b526a42d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#5) Преобразуйте все сообщения в вектора TF-IDF.\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "#При построении словаря игнорируйте термины, частота которых в документе строго 15 (min_df = 15).\n",
    "#Подбирается экспериментальным путем. Ориентируемся на максимальный коэф-т детерминации\n",
    "tfidf = TfidfVectorizer(min_df = 15)\n",
    "tfidf_matrix = tfidf.fit_transform(df.Message_clear)\n",
    "names = tfidf.get_feature_names()\n",
    "tfidf_matrix = pd.DataFrame(tfidf_matrix.toarray(), columns=names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 845,
   "id": "59f464e3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>000</th>\n",
       "      <th>08000839402</th>\n",
       "      <th>08000930705</th>\n",
       "      <th>10</th>\n",
       "      <th>100</th>\n",
       "      <th>1000</th>\n",
       "      <th>10p</th>\n",
       "      <th>11</th>\n",
       "      <th>12hrs</th>\n",
       "      <th>150</th>\n",
       "      <th>...</th>\n",
       "      <th>yeah</th>\n",
       "      <th>year</th>\n",
       "      <th>yes</th>\n",
       "      <th>yesterday</th>\n",
       "      <th>yet</th>\n",
       "      <th>yo</th>\n",
       "      <th>you</th>\n",
       "      <th>your</th>\n",
       "      <th>yr</th>\n",
       "      <th>yup</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 692 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   000  08000839402  08000930705   10  100  1000  10p   11  12hrs  150  ...  \\\n",
       "0  0.0          0.0          0.0  0.0  0.0   0.0  0.0  0.0    0.0  0.0  ...   \n",
       "1  0.0          0.0          0.0  0.0  0.0   0.0  0.0  0.0    0.0  0.0  ...   \n",
       "2  0.0          0.0          0.0  0.0  0.0   0.0  0.0  0.0    0.0  0.0  ...   \n",
       "3  0.0          0.0          0.0  0.0  0.0   0.0  0.0  0.0    0.0  0.0  ...   \n",
       "4  0.0          0.0          0.0  0.0  0.0   0.0  0.0  0.0    0.0  0.0  ...   \n",
       "\n",
       "   yeah  year  yes  yesterday  yet   yo  you  your   yr  yup  \n",
       "0   0.0   0.0  0.0        0.0  0.0  0.0  0.0   0.0  0.0  0.0  \n",
       "1   0.0   0.0  0.0        0.0  0.0  0.0  0.0   0.0  0.0  0.0  \n",
       "2   0.0   0.0  0.0        0.0  0.0  0.0  0.0   0.0  0.0  0.0  \n",
       "3   0.0   0.0  0.0        0.0  0.0  0.0  0.0   0.0  0.0  0.0  \n",
       "4   0.0   0.0  0.0        0.0  0.0  0.0  0.0   0.0  0.0  0.0  \n",
       "\n",
       "[5 rows x 692 columns]"
      ]
     },
     "execution_count": 845,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tfidf_matrix.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 846,
   "id": "b775223b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#6)Разделяем данные на тестовые и тренировочные в соотношении 30/70, \n",
    "#указывем random_state=42. Используем train_test_split\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 847,
   "id": "7b2a9dee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# в X записываем саму матрицу, а в у (то, что мы должны будем по итогу  правильно предсказывать) -  тип сообщения ham или spam \n",
    "#из датафрейма df, столбец 'Category'\n",
    "X = tfidf_matrix\n",
    "y = df['Category']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.30, random_state=42)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 848,
   "id": "30a2224f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression()"
      ]
     },
     "execution_count": 848,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Построим модель логистической регрессии, оцениваем ее точность на тестовых данных\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "model = LogisticRegression()\n",
    "model.fit(X_train, y_train)  # метод обучается на данных и подбирает оптимальные коэффициенты"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 850,
   "id": "01be6e4e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-2.90812655])"
      ]
     },
     "execution_count": 850,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.intercept_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 851,
   "id": "a2c03ebc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['ham', 'ham', 'ham', ..., 'ham', 'spam', 'ham'], dtype=object)"
      ]
     },
     "execution_count": 851,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Вычисляем категориальные значения y_pred, используя тестовые данные X_test\n",
    "y_pred = model.predict(X_test)\n",
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 852,
   "id": "93e9bff7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9772727272727273"
      ]
     },
     "execution_count": 852,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.score(X_test, y_test) # метод возвращает значение коэффициента детерминации"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb79fc2e",
   "metadata": {},
   "source": [
    "у нас коэффициент детерминации близок к 1, значит логистическая регрессия очень хорошо объясняет закономернось данных"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 853,
   "id": "9b0433b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#8) Опишите результаты при помощи confusion_matrix\n",
    "from sklearn.metrics import confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 854,
   "id": "ff8fd89f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1672"
      ]
     },
     "execution_count": 854,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#смотрим длину тестовой выборуи\n",
    "len(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 855,
   "id": "36f1eec3",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1443,    5],\n",
       "       [  33,  191]])"
      ]
     },
     "execution_count": 855,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusion_matrix(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc353b9e",
   "metadata": {},
   "source": [
    "#### Итого: из 1672 значений \n",
    "\n",
    "    1443 правильных результата\n",
    "    \n",
    "    5 ложноотрицательных результата\n",
    "    \n",
    "    33 ложно положительных срабатываний\n",
    "    \n",
    "    191 истинно отрицательных результатов"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 856,
   "id": "7ed89d9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#9) Постройте датафрейм, который будет содержать все исходные тексты сообщений, классифицированные \n",
    "# неправильно (с указанием фактического и предсказанного).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 857,
   "id": "3651b416",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Category</th>\n",
       "      <th>Message</th>\n",
       "      <th>Message_clear</th>\n",
       "      <th>Category_pred</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3245</th>\n",
       "      <td>ham</td>\n",
       "      <td>Squeeeeeze!! This is christmas hug.. If u lik ...</td>\n",
       "      <td>squeeeeeze is christmas hug u lik frndshp den ...</td>\n",
       "      <td>ham</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>944</th>\n",
       "      <td>ham</td>\n",
       "      <td>And also I've sorta blown him off a couple tim...</td>\n",
       "      <td>also ve sorta blown off couple time recently i...</td>\n",
       "      <td>ham</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1044</th>\n",
       "      <td>ham</td>\n",
       "      <td>Mmm thats better now i got a roast down me! i...</td>\n",
       "      <td>mmm thats better got roast me i d b better i a...</td>\n",
       "      <td>ham</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2484</th>\n",
       "      <td>ham</td>\n",
       "      <td>Mm have some kanji dont eat anything heavy ok</td>\n",
       "      <td>mm some kanji dont eat anything heavy ok</td>\n",
       "      <td>ham</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>812</th>\n",
       "      <td>ham</td>\n",
       "      <td>So there's a ring that comes with the guys cos...</td>\n",
       "      <td>a ring come the guy costume s there so can gif...</td>\n",
       "      <td>ham</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Category                                            Message  \\\n",
       "3245      ham  Squeeeeeze!! This is christmas hug.. If u lik ...   \n",
       "944       ham  And also I've sorta blown him off a couple tim...   \n",
       "1044      ham  Mmm thats better now i got a roast down me! i...   \n",
       "2484      ham      Mm have some kanji dont eat anything heavy ok   \n",
       "812       ham  So there's a ring that comes with the guys cos...   \n",
       "\n",
       "                                          Message_clear Category_pred  \n",
       "3245  squeeeeeze is christmas hug u lik frndshp den ...           ham  \n",
       "944   also ve sorta blown off couple time recently i...           ham  \n",
       "1044  mmm thats better got roast me i d b better i a...           ham  \n",
       "2484           mm some kanji dont eat anything heavy ok           ham  \n",
       "812   a ring come the guy costume s there so can gif...           ham  "
      ]
     },
     "execution_count": 857,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Отфильтруем исходный датафрейм df, оставим в нем только данные, которые попали в выборку X_test\n",
    "ind_list = list(X_test.index.values)\n",
    "df_X_test= pd.DataFrame(data=df, index=ind_list)\n",
    "#создадим датафрейм с предсказанными значениями y_pred\n",
    "df_y_pred= pd.DataFrame(data=y_pred, index=ind_list, columns =['Category_pred'])\n",
    "#объединим этих два датафрейма\n",
    "df_diff = pd.concat([df_X_test, df_y_pred], axis=1)\n",
    "df_diff.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 858,
   "id": "0752411f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Category</th>\n",
       "      <th>Message</th>\n",
       "      <th>Message_clear</th>\n",
       "      <th>Category_pred</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>881</th>\n",
       "      <td>spam</td>\n",
       "      <td>Reminder: You have not downloaded the content ...</td>\n",
       "      <td>reminder have downloaded content have already ...</td>\n",
       "      <td>ham</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3864</th>\n",
       "      <td>spam</td>\n",
       "      <td>Oh my god! I've found your number again! I'm s...</td>\n",
       "      <td>oh god ve found number i so glad text back xaf...</td>\n",
       "      <td>ham</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2575</th>\n",
       "      <td>spam</td>\n",
       "      <td>Your next amazing xxx PICSFREE1 video will be ...</td>\n",
       "      <td>next amazing xxx picsfree1 video be sent you e...</td>\n",
       "      <td>ham</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3548</th>\n",
       "      <td>spam</td>\n",
       "      <td>Rock yr chik. Get 100's of filthy films &amp;XXX p...</td>\n",
       "      <td>rock yr chik get 100 of filthy film xxx pic yr...</td>\n",
       "      <td>ham</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2402</th>\n",
       "      <td>spam</td>\n",
       "      <td>Babe: U want me dont u baby! Im nasty and have...</td>\n",
       "      <td>babe u want dont u baby im nasty have thing 4 ...</td>\n",
       "      <td>ham</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2663</th>\n",
       "      <td>spam</td>\n",
       "      <td>Hello darling how are you today? I would love ...</td>\n",
       "      <td>hello darling are today would love have chat d...</td>\n",
       "      <td>ham</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>751</th>\n",
       "      <td>spam</td>\n",
       "      <td>Do you realize that in about 40 years, we'll h...</td>\n",
       "      <td>you realize in 40 year ll thousand old lady ru...</td>\n",
       "      <td>ham</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2364</th>\n",
       "      <td>spam</td>\n",
       "      <td>Fantasy Football is back on your TV. Go to Sky...</td>\n",
       "      <td>fantasy football back your tv go sky gamestar ...</td>\n",
       "      <td>ham</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3463</th>\n",
       "      <td>spam</td>\n",
       "      <td>Bloomberg -Message center +447797706009 Why wa...</td>\n",
       "      <td>bloomberg message center 447797706009 wait app...</td>\n",
       "      <td>ham</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>227</th>\n",
       "      <td>spam</td>\n",
       "      <td>Will u meet ur dream partner soon? Is ur caree...</td>\n",
       "      <td>u meet ur dream partner soon ur career 2 flyng...</td>\n",
       "      <td>ham</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3885</th>\n",
       "      <td>spam</td>\n",
       "      <td>A link to your picture has been sent. You can ...</td>\n",
       "      <td>link your picture been sent can also use http ...</td>\n",
       "      <td>ham</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3755</th>\n",
       "      <td>spam</td>\n",
       "      <td>Bloomberg -Message center +447797706009 Why wa...</td>\n",
       "      <td>bloomberg message center 447797706009 wait app...</td>\n",
       "      <td>ham</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>505</th>\n",
       "      <td>spam</td>\n",
       "      <td>#ERROR!</td>\n",
       "      <td>error</td>\n",
       "      <td>ham</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>856</th>\n",
       "      <td>spam</td>\n",
       "      <td>Talk sexy!! Make new friends or fall in love i...</td>\n",
       "      <td>talk sexy make new friend fall love the world ...</td>\n",
       "      <td>ham</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3360</th>\n",
       "      <td>spam</td>\n",
       "      <td>Sorry I missed your call let's talk when you h...</td>\n",
       "      <td>sorry missed call let talk you the time m 0709...</td>\n",
       "      <td>ham</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4506</th>\n",
       "      <td>spam</td>\n",
       "      <td>Mobile Club: Choose any of the top quality ite...</td>\n",
       "      <td>mobile club choose of top quality item your mo...</td>\n",
       "      <td>ham</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5037</th>\n",
       "      <td>spam</td>\n",
       "      <td>You won't believe it but it's true. It's Incre...</td>\n",
       "      <td>won believe but s true s incredible txts reply...</td>\n",
       "      <td>ham</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2770</th>\n",
       "      <td>spam</td>\n",
       "      <td>Burger King - Wanna play footy at a top stadiu...</td>\n",
       "      <td>burger king wanna play footy a top stadium get...</td>\n",
       "      <td>ham</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2124</th>\n",
       "      <td>spam</td>\n",
       "      <td>#ERROR!</td>\n",
       "      <td>error</td>\n",
       "      <td>ham</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5120</th>\n",
       "      <td>spam</td>\n",
       "      <td>PRIVATE! Your 2003 Account Statement for 078</td>\n",
       "      <td>private 2003 account statement 078</td>\n",
       "      <td>ham</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1988</th>\n",
       "      <td>ham</td>\n",
       "      <td>No calls..messages..missed calls</td>\n",
       "      <td>call message missed call</td>\n",
       "      <td>spam</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1350</th>\n",
       "      <td>spam</td>\n",
       "      <td>FREE2DAY sexy St George's Day pic of Jordan!Tx...</td>\n",
       "      <td>free2day sexy st george day pic jordan txt pic...</td>\n",
       "      <td>ham</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1097</th>\n",
       "      <td>spam</td>\n",
       "      <td>Dear Subscriber ur draw 4 £100 gift voucher wi...</td>\n",
       "      <td>dear subscriber ur draw 4 100 gift voucher b e...</td>\n",
       "      <td>ham</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>731</th>\n",
       "      <td>spam</td>\n",
       "      <td>Email AlertFrom: Jeri StewartSize: 2KBSubject:...</td>\n",
       "      <td>email alertfrom jeri stewartsize 2kbsubject lo...</td>\n",
       "      <td>ham</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1893</th>\n",
       "      <td>spam</td>\n",
       "      <td>CALL 09090900040 &amp; LISTEN TO EXTREME DIRTY LIV...</td>\n",
       "      <td>call 09090900040 listen extreme dirty live cha...</td>\n",
       "      <td>ham</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>415</th>\n",
       "      <td>spam</td>\n",
       "      <td>100 dating service cal;l 09064012103 box334sk38ch</td>\n",
       "      <td>100 dating service cal l 09064012103 box334sk38ch</td>\n",
       "      <td>ham</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2699</th>\n",
       "      <td>spam</td>\n",
       "      <td>FROM 88066 LOST £12 HELP</td>\n",
       "      <td>88066 lost 12 help</td>\n",
       "      <td>ham</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75</th>\n",
       "      <td>ham</td>\n",
       "      <td>I am waiting machan. Call me once you free.</td>\n",
       "      <td>am waiting machan call once free</td>\n",
       "      <td>spam</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68</th>\n",
       "      <td>spam</td>\n",
       "      <td>Did you hear about the new \"Divorce Barbie\"? I...</td>\n",
       "      <td>you hear the new divorce barbie come all ken s...</td>\n",
       "      <td>ham</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5377</th>\n",
       "      <td>spam</td>\n",
       "      <td>The current leading bid is 151. To pause this ...</td>\n",
       "      <td>current leading bid 151 pause auction send cus...</td>\n",
       "      <td>ham</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>ham</td>\n",
       "      <td>No calls..messages..missed calls</td>\n",
       "      <td>call message missed call</td>\n",
       "      <td>spam</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3132</th>\n",
       "      <td>spam</td>\n",
       "      <td>LookAtMe!: Thanks for your purchase of a video...</td>\n",
       "      <td>lookatme thanks your purchase video clip looka...</td>\n",
       "      <td>ham</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>spam</td>\n",
       "      <td>England v Macedonia - dont miss the goals/team...</td>\n",
       "      <td>england v macedonia dont miss goal team news t...</td>\n",
       "      <td>ham</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4783</th>\n",
       "      <td>ham</td>\n",
       "      <td>Call me, i am senthil from hsbc.</td>\n",
       "      <td>call i senthil hsbc</td>\n",
       "      <td>spam</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3692</th>\n",
       "      <td>ham</td>\n",
       "      <td>Sir, i am waiting for your call, once free ple...</td>\n",
       "      <td>sir am waiting your call free please call</td>\n",
       "      <td>spam</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>191</th>\n",
       "      <td>spam</td>\n",
       "      <td>Are you unique enough? Find out from 30th Augu...</td>\n",
       "      <td>you unique enough find from 30th august www ar...</td>\n",
       "      <td>ham</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4543</th>\n",
       "      <td>spam</td>\n",
       "      <td>FreeMsg Hi baby wow just got a new cam moby. W...</td>\n",
       "      <td>freemsg hi baby wow got new cam moby wanna c h...</td>\n",
       "      <td>ham</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>305</th>\n",
       "      <td>spam</td>\n",
       "      <td>SMS. ac Blind Date 4U!: Rodds1 is 21/m from Ab...</td>\n",
       "      <td>sm ac blind date 4u rodds1 21 from aberdeen un...</td>\n",
       "      <td>ham</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Category                                            Message  \\\n",
       "881      spam  Reminder: You have not downloaded the content ...   \n",
       "3864     spam  Oh my god! I've found your number again! I'm s...   \n",
       "2575     spam  Your next amazing xxx PICSFREE1 video will be ...   \n",
       "3548     spam  Rock yr chik. Get 100's of filthy films &XXX p...   \n",
       "2402     spam  Babe: U want me dont u baby! Im nasty and have...   \n",
       "2663     spam  Hello darling how are you today? I would love ...   \n",
       "751      spam  Do you realize that in about 40 years, we'll h...   \n",
       "2364     spam  Fantasy Football is back on your TV. Go to Sky...   \n",
       "3463     spam  Bloomberg -Message center +447797706009 Why wa...   \n",
       "227      spam  Will u meet ur dream partner soon? Is ur caree...   \n",
       "3885     spam  A link to your picture has been sent. You can ...   \n",
       "3755     spam  Bloomberg -Message center +447797706009 Why wa...   \n",
       "505      spam                                            #ERROR!   \n",
       "856      spam  Talk sexy!! Make new friends or fall in love i...   \n",
       "3360     spam  Sorry I missed your call let's talk when you h...   \n",
       "4506     spam  Mobile Club: Choose any of the top quality ite...   \n",
       "5037     spam  You won't believe it but it's true. It's Incre...   \n",
       "2770     spam  Burger King - Wanna play footy at a top stadiu...   \n",
       "2124     spam                                            #ERROR!   \n",
       "5120     spam       PRIVATE! Your 2003 Account Statement for 078   \n",
       "1988      ham                   No calls..messages..missed calls   \n",
       "1350     spam  FREE2DAY sexy St George's Day pic of Jordan!Tx...   \n",
       "1097     spam  Dear Subscriber ur draw 4 £100 gift voucher wi...   \n",
       "731      spam  Email AlertFrom: Jeri StewartSize: 2KBSubject:...   \n",
       "1893     spam  CALL 09090900040 & LISTEN TO EXTREME DIRTY LIV...   \n",
       "415      spam  100 dating service cal;l 09064012103 box334sk38ch   \n",
       "2699     spam                           FROM 88066 LOST £12 HELP   \n",
       "75        ham        I am waiting machan. Call me once you free.   \n",
       "68       spam  Did you hear about the new \"Divorce Barbie\"? I...   \n",
       "5377     spam  The current leading bid is 151. To pause this ...   \n",
       "45        ham                   No calls..messages..missed calls   \n",
       "3132     spam  LookAtMe!: Thanks for your purchase of a video...   \n",
       "19       spam  England v Macedonia - dont miss the goals/team...   \n",
       "4783      ham                   Call me, i am senthil from hsbc.   \n",
       "3692      ham  Sir, i am waiting for your call, once free ple...   \n",
       "191      spam  Are you unique enough? Find out from 30th Augu...   \n",
       "4543     spam  FreeMsg Hi baby wow just got a new cam moby. W...   \n",
       "305      spam  SMS. ac Blind Date 4U!: Rodds1 is 21/m from Ab...   \n",
       "\n",
       "                                          Message_clear Category_pred  \n",
       "881   reminder have downloaded content have already ...           ham  \n",
       "3864  oh god ve found number i so glad text back xaf...           ham  \n",
       "2575  next amazing xxx picsfree1 video be sent you e...           ham  \n",
       "3548  rock yr chik get 100 of filthy film xxx pic yr...           ham  \n",
       "2402  babe u want dont u baby im nasty have thing 4 ...           ham  \n",
       "2663  hello darling are today would love have chat d...           ham  \n",
       "751   you realize in 40 year ll thousand old lady ru...           ham  \n",
       "2364  fantasy football back your tv go sky gamestar ...           ham  \n",
       "3463  bloomberg message center 447797706009 wait app...           ham  \n",
       "227   u meet ur dream partner soon ur career 2 flyng...           ham  \n",
       "3885  link your picture been sent can also use http ...           ham  \n",
       "3755  bloomberg message center 447797706009 wait app...           ham  \n",
       "505                                              error            ham  \n",
       "856   talk sexy make new friend fall love the world ...           ham  \n",
       "3360  sorry missed call let talk you the time m 0709...           ham  \n",
       "4506  mobile club choose of top quality item your mo...           ham  \n",
       "5037  won believe but s true s incredible txts reply...           ham  \n",
       "2770  burger king wanna play footy a top stadium get...           ham  \n",
       "2124                                             error            ham  \n",
       "5120                 private 2003 account statement 078           ham  \n",
       "1988                           call message missed call          spam  \n",
       "1350  free2day sexy st george day pic jordan txt pic...           ham  \n",
       "1097  dear subscriber ur draw 4 100 gift voucher b e...           ham  \n",
       "731   email alertfrom jeri stewartsize 2kbsubject lo...           ham  \n",
       "1893  call 09090900040 listen extreme dirty live cha...           ham  \n",
       "415   100 dating service cal l 09064012103 box334sk38ch           ham  \n",
       "2699                                 88066 lost 12 help           ham  \n",
       "75                    am waiting machan call once free           spam  \n",
       "68    you hear the new divorce barbie come all ken s...           ham  \n",
       "5377  current leading bid 151 pause auction send cus...           ham  \n",
       "45                             call message missed call          spam  \n",
       "3132  lookatme thanks your purchase video clip looka...           ham  \n",
       "19    england v macedonia dont miss goal team news t...           ham  \n",
       "4783                               call i senthil hsbc           spam  \n",
       "3692         sir am waiting your call free please call           spam  \n",
       "191   you unique enough find from 30th august www ar...           ham  \n",
       "4543  freemsg hi baby wow got new cam moby wanna c h...           ham  \n",
       "305   sm ac blind date 4u rodds1 21 from aberdeen un...           ham  "
      ]
     },
     "execution_count": 858,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#оставим только строчки, в которых фактическая категория (Category) не равна предсказанной категории (Category_pred)\n",
    "df_diff.loc[df_diff['Category'] != df_diff['Category_pred']]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
